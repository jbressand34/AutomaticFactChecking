{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim import corpora, models, similarities\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  snippet_id                                    snippet_content\n",
      "0           0         968  ['past', 'week', 'republican', 'members_congre...\n",
      "1           1         969  ['european_union', 'long_criticized', 'east_eu...\n",
      "   claim_id  Unnamed: 0                                      claim_content\n",
      "0         9           0     ['taxes', 'spent', 'so_called', \"'war_terror\"]\n",
      "1        18         134  ['says', 'north_korea', 'agreed_denuclearizati...\n"
     ]
    }
   ],
   "source": [
    "df_bow_snippets = pd.read_csv('datasets/bag_of_word_snippets.csv')\n",
    "df_bow_claims = pd.read_csv('datasets/bag_of_word_claims.csv')\n",
    "df_bow_claims = df_bow_claims.groupby('claim_id').first().reset_index()\n",
    "print(df_bow_snippets.head(2))\n",
    "print(df_bow_claims.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow_snippets['snippet_content'] = df_bow_snippets['snippet_content'].apply(lambda st: ast.literal_eval(st))\n",
    "df_bow_claims['claim_content'] = df_bow_claims['claim_content'].apply(lambda st: ast.literal_eval(st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>snippet_id</th>\n",
       "      <th>groundtruth_label</th>\n",
       "      <th>claim_id</th>\n",
       "      <th>snippet_date</th>\n",
       "      <th>claim_content</th>\n",
       "      <th>snippet_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>887759</td>\n",
       "      <td>True</td>\n",
       "      <td>4229</td>\n",
       "      <td>16577</td>\n",
       "      <td>We spend more money on lobbying than we do on ...</td>\n",
       "      <td>22/05/2015 · Will London's mayor put the brake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>887760</td>\n",
       "      <td>False</td>\n",
       "      <td>4229</td>\n",
       "      <td>16577</td>\n",
       "      <td>We spend more money on lobbying than we do on ...</td>\n",
       "      <td>22/05/2015 · ... Facebook for First Draft upda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  snippet_id  groundtruth_label  claim_id  snippet_date  \\\n",
       "0           0      887759               True      4229         16577   \n",
       "1           1      887760              False      4229         16577   \n",
       "\n",
       "                                       claim_content  \\\n",
       "0  We spend more money on lobbying than we do on ...   \n",
       "1  We spend more money on lobbying than we do on ...   \n",
       "\n",
       "                                     snippet_content  \n",
       "0  22/05/2015 · Will London's mayor put the brake...  \n",
       "1  22/05/2015 · ... Facebook for First Draft upda...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groundtruth = pd.read_csv('datasets/relevance_discovery_groundtruth.csv')\n",
    "df_groundtruth.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow_snippets = df_bow_snippets[['snippet_id','snippet_content']]\n",
    "df_bow_snippets.columns = ['snippet_id','snippet_bow']\n",
    "\n",
    "df_bow_claims = df_bow_claims[['claim_id','claim_content']]\n",
    "df_bow_claims.columns = ['claim_id','claim_bow']\n",
    "\n",
    "df_groundtruth = df_groundtruth[['claim_id','snippet_id','groundtruth_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>snippet_id</th>\n",
       "      <th>groundtruth_label</th>\n",
       "      <th>snippet_bow</th>\n",
       "      <th>claim_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4229</td>\n",
       "      <td>887759</td>\n",
       "      <td>True</td>\n",
       "      <td>[london, mayor, put, brakes, better, ways, spo...</td>\n",
       "      <td>[spend, money, lobbying, campaigns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4229</td>\n",
       "      <td>887760</td>\n",
       "      <td>False</td>\n",
       "      <td>[facebook, first, draft, updates, liberals, sp...</td>\n",
       "      <td>[spend, money, lobbying, campaigns]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claim_id  snippet_id  groundtruth_label  \\\n",
       "0      4229      887759               True   \n",
       "1      4229      887760              False   \n",
       "\n",
       "                                         snippet_bow  \\\n",
       "0  [london, mayor, put, brakes, better, ways, spo...   \n",
       "1  [facebook, first, draft, updates, liberals, sp...   \n",
       "\n",
       "                             claim_bow  \n",
       "0  [spend, money, lobbying, campaigns]  \n",
       "1  [spend, money, lobbying, campaigns]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = pd.merge(pd.merge(df_groundtruth, df_bow_snippets), df_bow_claims)\n",
    "print(len(df_merge))\n",
    "df_merge.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nb_word in sorted(list(np.arange(10000,40000,5000)),reverse=True):\n",
    "    dictionary = corpora.Dictionary.load('dictionaries/factchecking_'+str(nb_word/1000)+'.dict')\n",
    "    #tfidf = models.TfidfModel.load('topic_models/'+str(nb_word/1000)+'.tfidf')\n",
    "    \n",
    "    df_merge['snippet_bow_'+str(nb_word/1000)] = df_merge['snippet_bow'].apply(lambda x: dictionary.doc2bow(x))\n",
    "    tfidf = models.TfidfModel(list(df_merge['snippet_bow_'+str(nb_word/1000)].as_matrix()))\n",
    "    \n",
    "    df_merge['claim_bow_'+str(nb_word/1000)] = df_merge['claim_bow'].apply(lambda x: dictionary.doc2bow(x))\n",
    "    df_merge['claim_tfidf_'+str(nb_word/1000)] = df_merge['claim_bow_'+str(nb_word/1000)].apply(lambda x: tfidf[x])\n",
    "    \n",
    "    df_merge['snippet_tfidf_'+str(nb_word/1000)] = df_merge['snippet_bow_'+str(nb_word/1000)].apply(lambda x: tfidf[x])\n",
    "    \"\"\"\n",
    "    for nb_topic in np.arange(100,350,50):\n",
    "        \n",
    "        lsi = models.LsiModel.load('topic_models/'+str(nb_word/1000)+'_'+str(nb_topic)+'.lsi')\n",
    "        rp = models.RpModel.load('topic_models/'+str(nb_word/1000)+'_'+str(nb_topic)+'.rp')\n",
    "        lda = models.RpModel.load('topic_models/'+str(nb_word/1000)+'_'+str(nb_topic)+'.lda')\n",
    "        \n",
    "        df_merge['claim_lsi_'+str(nb_word/1000)+'_'+str(nb_topic)] = \\\n",
    "        df_merge['claim_tfidf_'+str(nb_word/1000)].apply(lambda x: lsi[x])\n",
    "        df_merge['claim_rp_'+str(nb_word/1000)+'_'+str(nb_topic)] = \\\n",
    "        df_merge['claim_bow_'+str(nb_word/1000)].apply(lambda x: rp[x])\n",
    "        df_merge['claim_lda_'+str(nb_word/1000)+'_'+str(nb_topic)] = \\\n",
    "        df_merge['claim_bow_'+str(nb_word/1000)].apply(lambda x: lda[x])\n",
    "        \n",
    "        df_merge['snippet_lsi_'+str(nb_word/1000)+'_'+str(nb_topic)] = \\\n",
    "        df_merge['snippet_tfidf_'+str(nb_word/1000)].apply(lambda x: lsi[x])\n",
    "        df_merge['snippet_rp_'+str(nb_word/1000)+'_'+str(nb_topic)] = \\\n",
    "        df_merge['snippet_bow_'+str(nb_word/1000)].apply(lambda x: rp[x])\n",
    "        df_merge['snippet_lda_'+str(nb_word/1000)+'_'+str(nb_topic)] = \\\n",
    "        df_merge['snippet_bow_'+str(nb_word/1000)].apply(lambda x: lda[x])\n",
    "    \"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14203, 13683, 11160, 5779, 4338, 4229, 1085, 292, 187, 121]\n"
     ]
    }
   ],
   "source": [
    "claim_ids = sorted(list(df_merge['claim_id'].unique()),reverse=True)\n",
    "print(claim_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_similarities = {}\n",
    "\n",
    "dic_similarities['snippet_id'] = list(df_merge[['claim_id','snippet_id']]\\\n",
    ".sort_values(by=['claim_id','snippet_id'],ascending=False)['snippet_id'].as_matrix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nb_word in sorted(list(np.arange(10000,40000,5000)),reverse=True):\n",
    "    \"\"\"\n",
    "    for nb_topic in np.arange(100,350,50):\n",
    "        lsi = models.LsiModel.load('topic_models/'+str(nb_word/1000)+'_'+str(nb_topic)+'.lsi')\n",
    "        rp = models.RpModel.load('topic_models/'+str(nb_word/1000)+'_'+str(nb_topic)+'.rp')\n",
    "        lda = models.RpModel.load('topic_models/'+str(nb_word/1000)+'_'+str(nb_topic)+'.lda')\n",
    "    \n",
    "        dic_similarities['lsi'+str(nb_word/1000)+'_'+str(nb_topic)] = []\n",
    "        dic_similarities['rp'+str(nb_word/1000)+'_'+str(nb_topic)] = []\n",
    "        dic_similarities['lda'+str(nb_word/1000)+'_'+str(nb_topic)] = []\n",
    "        print(\"Beginning nb topic = \"+str(nb_topic))\n",
    "        for claim_id in claim_ids:\n",
    "            df_ = df_merge[df_merge['claim_id']==claim_id][['snippet_id','snippet_bow_'+str(nb_word/1000),\n",
    "                                                                        'snippet_tfidf_'+str(nb_word/1000),\n",
    "                                                                    'claim_bow_'+str(nb_word/1000),\n",
    "                                                                        'claim_tfidf_'+str(nb_word/1000)]]\\\n",
    "            .sort_values(by=['snippet_id'],ascending=False)\n",
    "            claim_bow = list(df_['claim_bow_'+str(nb_word/1000)].as_matrix())[0]\n",
    "            claim_tfidf = list(df_['claim_tfidf_'+str(nb_word/1000)].as_matrix())[0]\n",
    "        \n",
    "            snippet_bow = list(df_['snippet_bow_'+str(nb_word/1000)].as_matrix())\n",
    "            snippet_tfidf = list(df_['snippet_tfidf_'+str(nb_word/1000)].as_matrix())\n",
    "        \n",
    "            lsi_index = similarities.MatrixSimilarity(lsi[snippet_tfidf])\n",
    "            rp_index = similarities.MatrixSimilarity(rp[snippet_bow])\n",
    "            lda_index = similarities.MatrixSimilarity(lda[snippet_bow])\n",
    "        \n",
    "            sims_lsi = lsi_index[lsi[claim_tfidf]]\n",
    "            sims_rp = rp_index[rp[claim_bow]]\n",
    "            sims_lda = lda_index[lda[claim_bow]]\n",
    "        \n",
    "            for i in range(0,len(snippet_bow)):\n",
    "                dic_similarities['lsi'+str(nb_word/1000)+'_'+str(nb_topic)].append(sims_lsi[i])\n",
    "                dic_similarities['rp'+str(nb_word/1000)+'_'+str(nb_topic)].append(sims_rp[i])\n",
    "                dic_similarities['lda'+str(nb_word/1000)+'_'+str(nb_topic)].append(sims_lda[i])\n",
    "    \"\"\"\n",
    "    dic_similarities['bow'+str(nb_word/1000)] = []\n",
    "    dic_similarities['tfidf'+str(nb_word/1000)] = []\n",
    "    for claim_id in claim_ids:\n",
    "        df_ = df_merge[df_merge['claim_id']==claim_id][['snippet_id','snippet_bow_'+str(nb_word/1000),\n",
    "                                                                        'snippet_tfidf_'+str(nb_word/1000),\n",
    "                                                                    'claim_bow_'+str(nb_word/1000),\n",
    "                                                                        'claim_tfidf_'+str(nb_word/1000)]]\\\n",
    "        .sort_values(by=['snippet_id'],ascending=False)\n",
    "        claim_bow = list(df_['claim_bow_'+str(nb_word/1000)].as_matrix())[0]\n",
    "        claim_tfidf = list(df_['claim_tfidf_'+str(nb_word/1000)].as_matrix())[0]\n",
    "        snippet_bow = list(df_['snippet_bow_'+str(nb_word/1000)].as_matrix())\n",
    "        snippet_tfidf = list(df_['snippet_tfidf_'+str(nb_word/1000)].as_matrix())\n",
    "        index_bow = similarities.MatrixSimilarity(snippet_bow)\n",
    "        index_tfidf = similarities.MatrixSimilarity(snippet_tfidf)\n",
    "        sims_bow = index_bow[claim_bow]\n",
    "        sims_tfidf = index_tfidf[claim_tfidf]\n",
    "        for i in range(0,len(snippet_bow)):\n",
    "            dic_similarities['bow'+str(nb_word/1000)].append(sims_bow[i])\n",
    "            dic_similarities['tfidf'+str(nb_word/1000)].append(sims_tfidf[i])\n",
    "            \n",
    "df_similarities = pd.DataFrame(dic_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_final = pd.merge(df_merge[['snippet_id','groundtruth_label']], df_similarities)\n",
    "df_results_final.to_csv('datasets/similarity_results_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
